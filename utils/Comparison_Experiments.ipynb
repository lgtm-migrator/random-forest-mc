{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template \n",
    "\n",
    "- Author: Israel Oliveira [\\[e-mail\\]](mailto:'Israel%20Oliveira%20'<prof.israel@gmail.com>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T18:22:10.352863Z",
     "iopub.status.busy": "2021-09-20T18:22:10.352595Z",
     "iopub.status.idle": "2021-09-20T18:22:13.671687Z",
     "shell.execute_reply": "2021-09-20T18:22:13.671049Z",
     "shell.execute_reply.started": "2021-09-20T18:22:10.352790Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting random-forest-mc\n",
      "  Downloading random_forest_mc-0.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/site-packages (from random-forest-mc) (1.20.3)\n",
      "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.9/site-packages (from random-forest-mc) (1.3.2)\n",
      "Requirement already satisfied: tqdm>=4.60 in /usr/local/lib/python3.9/site-packages (from random-forest-mc) (4.62.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/site-packages (from pandas>=1.3->random-forest-mc) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/site-packages (from pandas>=1.3->random-forest-mc) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.3->random-forest-mc) (1.16.0)\n",
      "Installing collected packages: random-forest-mc\n",
      "Successfully installed random-forest-mc-0.3.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U random-forest-mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T18:22:22.804586Z",
     "iopub.status.busy": "2021-09-20T18:22:22.804340Z",
     "iopub.status.idle": "2021-09-20T18:22:22.824340Z",
     "shell.execute_reply": "2021-09-20T18:22:22.823804Z",
     "shell.execute_reply.started": "2021-09-20T18:22:22.804554Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T19:57:54.749946Z",
     "iopub.status.busy": "2021-09-20T19:57:54.749632Z",
     "iopub.status.idle": "2021-09-20T19:57:54.754803Z",
     "shell.execute_reply": "2021-09-20T19:57:54.754206Z",
     "shell.execute_reply.started": "2021-09-20T19:57:54.749911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random_forest_mc.model import RandomForestMC\n",
    "from random_forest_mc.utils import load_file_json, dump_file_json, LoadDicts\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score\n",
    "from collections import Counter\n",
    "import hashlib\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T18:51:18.991931Z",
     "iopub.status.busy": "2021-09-20T18:51:18.991703Z",
     "iopub.status.idle": "2021-09-20T18:51:18.997373Z",
     "shell.execute_reply": "2021-09-20T18:51:18.996825Z",
     "shell.execute_reply.started": "2021-09-20T18:51:18.991903Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# from glob import glob\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from matplotlib import rcParams\n",
    "# from cycler import cycler\n",
    "\n",
    "# rcParams['figure.figsize'] = 12, 8 # 18, 5\n",
    "# rcParams['axes.spines.top'] = False\n",
    "# rcParams['axes.spines.right'] = False\n",
    "# rcParams['axes.grid'] = True\n",
    "# rcParams['axes.prop_cycle'] = cycler(color=['#365977'])\n",
    "# rcParams['lines.linewidth'] = 2.5\n",
    "\n",
    "# import seaborn as sns\n",
    "# sns.set_theme()\n",
    "\n",
    "# pd.set_option(\"max_columns\", None)\n",
    "# pd.set_option(\"max_rows\", None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def md(arg):\n",
    "    display(Markdown(arg))\n",
    "\n",
    "# from pandas_profiling import ProfileReport\n",
    "# #report = ProfileReport(#DataFrame here#, minimal=True)\n",
    "# #report.to\n",
    "\n",
    "# import pyarrow.parquet as pq\n",
    "# #df = pq.ParquetDataset(path_to_folder_with_parquets, filesystem=None).read_pandas().to_pandas()\n",
    "\n",
    "# import json\n",
    "# def open_file_json(path,mode='r',var=None):\n",
    "#     if mode == 'w':\n",
    "#         with open(path,'w') as f:\n",
    "#             json.dump(var, f)\n",
    "#     if mode == 'r':\n",
    "#         with open(path,'r') as f:\n",
    "#             return json.load(f)\n",
    "\n",
    "# import functools\n",
    "# import operator\n",
    "# def flat(a):\n",
    "#     return functools.reduce(operator.iconcat, a, [])\n",
    "\n",
    "# import json\n",
    "# from glob import glob\n",
    "# from typing import NewType\n",
    "\n",
    "\n",
    "# DictsPathType = NewType(\"DictsPath\", str)\n",
    "\n",
    "\n",
    "# def open_file_json(path):\n",
    "#     with open(path, \"r\") as f:\n",
    "#         return json.load(f)\n",
    "\n",
    "# class LoadDicts:\n",
    "#     def __init__(self, dict_path: DictsPathType = \"./data\"):\n",
    "#         Dicts_glob = glob(f\"{dict_path}/*.json\")\n",
    "#         self.List = []\n",
    "#         self.Dict = {}\n",
    "#         for path_json in Dicts_glob:\n",
    "#             name = path_json.split(\"/\")[-1].replace(\".json\", \"\")\n",
    "#             self.List.append(name)\n",
    "#             self.Dict[name] = open_file_json(path_json)\n",
    "#             setattr(self, name, self.Dict[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T18:51:19.897932Z",
     "iopub.status.busy": "2021-09-20T18:51:19.897689Z",
     "iopub.status.idle": "2021-09-20T18:51:21.100017Z",
     "shell.execute_reply": "2021-09-20T18:51:21.099375Z",
     "shell.execute_reply.started": "2021-09-20T18:51:19.897903Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.9.7\n",
      "IPython version      : 7.27.0\n",
      "\n",
      "Compiler    : GCC 10.2.1 20210110\n",
      "OS          : Linux\n",
      "Release     : 5.11.0-7620-generic\n",
      "Machine     : x86_64\n",
      "Processor   : \n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 3c1a5a8fd4f67e59495a7826bcaa83ce3055e1b9\n",
      "\n",
      "Git repo: https://github.com/ysraell/random-forest-mc.git\n",
      "\n",
      "Git branch: main\n",
      "\n",
      "pandas: 1.3.2\n",
      "numpy : 1.20.3\n",
      "joblib: 1.0.1\n",
      "\n",
      "CPU\t: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz\n",
      "Mem:            31G\n",
      "Swap:          4.0G\n"
     ]
    }
   ],
   "source": [
    "# Run this cell before close.\n",
    "%watermark -d --iversion -b -r -g -m -v\n",
    "!cat /proc/cpuinfo |grep 'model name'|head -n 1 |sed -e 's/model\\ name/CPU/'\n",
    "!free -h |cut -d'i' -f1  |grep -v total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T20:09:03.423818Z",
     "iopub.status.busy": "2021-09-20T20:09:03.423096Z",
     "iopub.status.idle": "2021-09-20T20:09:03.429114Z",
     "shell.execute_reply": "2021-09-20T20:09:03.428565Z",
     "shell.execute_reply.started": "2021-09-20T20:09:03.423784Z"
    }
   },
   "outputs": [],
   "source": [
    "def dfany2dfnumeric(dfA, dfB):\n",
    "    for col in dfA.columns:\n",
    "        mapper = {val: i for i,val in enumerate(dfA[col].unique().tolist()+dfB[col].unique().tolist())}\n",
    "        dfA[col] = dfA[col].apply(lambda x: mapper[x])\n",
    "        dfB[col] = dfB[col].apply(lambda x: mapper[x])\n",
    "    return dfA, dfB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tinanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T20:09:51.749485Z",
     "iopub.status.busy": "2021-09-20T20:09:51.749237Z",
     "iopub.status.idle": "2021-09-20T20:09:51.779946Z",
     "shell.execute_reply": "2021-09-20T20:09:51.779163Z",
     "shell.execute_reply.started": "2021-09-20T20:09:51.749456Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dicts = LoadDicts(\"../tests/\")\n",
    "dataset_dict = dicts.datasets_metadata\n",
    "ds_name = \"titanic\"\n",
    "params = dataset_dict[ds_name]\n",
    "dataset = (\n",
    "    pd.read_csv(params[\"csv_path\"].replace('~','/work'))[params[\"ds_cols\"] + [params[\"target_col\"]]]\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "dataset[\"Age\"] = dataset[\"Age\"].astype(np.uint8)\n",
    "dataset[\"SibSp\"] = dataset[\"SibSp\"].astype(np.uint8)\n",
    "dataset[\"Pclass\"] = dataset[\"Pclass\"].astype(str)\n",
    "dataset[\"Fare\"] = dataset[\"Fare\"].astype(np.uint32)\n",
    "target_col = params['target_col']\n",
    "dataset = dataset[params['ds_cols']+[target_col]].dropna().reset_index(drop=True)\n",
    "dataset[target_col] = dataset[target_col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T20:12:42.477924Z",
     "iopub.status.busy": "2021-09-20T20:12:42.477722Z",
     "iopub.status.idle": "2021-09-20T20:12:54.215000Z",
     "shell.execute_reply": "2021-09-20T20:12:54.214120Z",
     "shell.execute_reply.started": "2021-09-20T20:12:42.477902Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01058db1a2c646b2b97213b2b8a824e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Planting the forest:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n",
      "/tmp/ipykernel_52/4177174917.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfA[col] = dfA[col].apply(lambda x: mapper[x])\n",
      "/tmp/ipykernel_52/4177174917.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfB[col] = dfB[col].apply(lambda x: mapper[x])\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.5\n",
    "max_test_size = 100\n",
    "max_train_size = 100\n",
    "#def fullCycleAnalysis(dataset,params,test_size_frac, max_test_size, max_train_size, split_seeds, )\n",
    "target_col = params['target_col']\n",
    "ds_cols = params[\"ds_cols\"]\n",
    "df_classes = [dataset.query(f'{target_col} == \"{target_val}\"').reset_index(drop=True).copy() for target_val in dataset[target_col].unique()]\n",
    "\n",
    "Results = []\n",
    "    \n",
    "# Each seed is a experiment.\n",
    "for seed in split_seeds:\n",
    "    \n",
    "    df_train_list = []\n",
    "    df_test_list = []\n",
    "    while df_classes:\n",
    "        df = df_classes.pop(0)\n",
    "        df_train, df_test = train_test_split(df, test_size=test_size, random_state=seed)\n",
    "        if df_train.shape[0] > max_train_size:\n",
    "            df_train = df_train.sample(n = max_train_size, random_state=seed)\n",
    "        if df_test.shape[0] > max_test_size:\n",
    "            df_test = df_test.sample(n = max_test_size, random_state=seed)\n",
    "        df_train_list.append(df_train.copy())\n",
    "        df_test_list.append(df_test.copy())\n",
    "        del df\n",
    "    dataset_train = pd.concat(df_train_list).sample(dataset_train.shape[0]).reset_index(drop=True).copy()\n",
    "    del df_train_list\n",
    "    dataset_test = pd.concat(df_test_list).sample(dataset_test.shape[0]).reset_index(drop=True).copy()\n",
    "    del df_test_list\n",
    "\n",
    "    y_test = dataset_test[target_col].tolist()\n",
    "    \n",
    "    # Training step\n",
    "    cls = RandomForestMC(\n",
    "        n_trees=64, target_col=target_col, max_discard_trees=2,\n",
    "        th_start=0.9999, batch_train_pclass = max_train_size // 2, batch_val_pclass = max_train_size // 2\n",
    "    )\n",
    "    cls.process_dataset(dataset_train)\n",
    "    cls.fitParallel(max_workers=16, thread_parallel_method=False)\n",
    "    y_pred = cls.testForest(dataset_test)\n",
    "    F1_M = f1_score(y_test, y_pred, average='macro')\n",
    "    AUC_ROC_M = roc_auc_score(y_test, y_pred, average='macro')\n",
    "    RECALL = recall_score(y_test, y_pred, pos_label='1')\n",
    "    TP_1 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '1'])/y_test.count('1')\n",
    "    TP_1 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '0'])/y_test.count('0')\n",
    "    \n",
    "    Results.append((seed, 'RFMC', F1_M, AUC_ROC_M, RECALL, TP_1))\n",
    "    \n",
    "    MLPC = MLPClassifier(hidden_layer_sizes=(200,), max_iter=10000)\n",
    "    dataset_train_num, dataset_test_num = dfany2dfnumeric(dataset_train[ds_cols], dataset_test[ds_cols])\n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(dataset_train_num[ds_cols].to_numpy())  \n",
    "    # X_train = scaler.transform(dataset_train_num[ds_cols].to_numpy())  \n",
    "    # X_test = scaler.transform(dataset_test_num[ds_cols].to_numpy())  \n",
    "    MLPC.fit(dataset_train_num[ds_cols].to_numpy(), dataset_train[target_col].to_numpy())\n",
    "    y_pred = MLPC.predict(dataset_test_num[ds_cols].to_numpy()).tolist()\n",
    "    F1_M = f1_score(y_test, y_pred, average='macro')\n",
    "    AUC_ROC_M = roc_auc_score(y_test, y_pred, average='macro')\n",
    "    RECALL = recall_score(y_test, y_pred, pos_label='1')\n",
    "    TP_1 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '1'])/y_test.count('1')\n",
    "    \n",
    "    Results.append((seed, 'MLPC', F1_M, AUC_ROC_M, RECALL, TP_1))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T20:12:54.217845Z",
     "iopub.status.busy": "2021-09-20T20:12:54.216980Z",
     "iopub.status.idle": "2021-09-20T20:12:54.225754Z",
     "shell.execute_reply": "2021-09-20T20:12:54.224847Z",
     "shell.execute_reply.started": "2021-09-20T20:12:54.217796Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(43, 'RFMC', 0.7740453415681253, 0.7749999999999999, 0.71, 0.71),\n",
       " (43, 'MLPC', 0.7799119647859143, 0.78, 0.76, 0.76)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Credit Card Fraude Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T18:22:30.898266Z",
     "iopub.status.busy": "2021-09-20T18:22:30.898033Z",
     "iopub.status.idle": "2021-09-20T18:22:32.271922Z",
     "shell.execute_reply": "2021-09-20T18:22:32.271312Z",
     "shell.execute_reply.started": "2021-09-20T18:22:30.898241Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/work/data/creditcard_trans_int.csv')\n",
    "target_col = 'Class'\n",
    "ds_cols = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
    "df[target_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T18:22:32.273160Z",
     "iopub.status.busy": "2021-09-20T18:22:32.272952Z",
     "iopub.status.idle": "2021-09-20T18:22:32.277598Z",
     "shell.execute_reply": "2021-09-20T18:22:32.276878Z",
     "shell.execute_reply.started": "2021-09-20T18:22:32.273138Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T18:27:23.423861Z",
     "iopub.status.busy": "2021-09-20T18:27:23.423651Z",
     "iopub.status.idle": "2021-09-20T18:27:23.431979Z",
     "shell.execute_reply": "2021-09-20T18:27:23.431427Z",
     "shell.execute_reply.started": "2021-09-20T18:27:23.423838Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How much for test step:\n",
    "N_fraud_test = 200\n",
    "N_truth_test = int(2e4)\n",
    "\n",
    "# How much for training step:\n",
    "N_truth_train = int(2e5)\n",
    "# The remaing data for fraud is all used.\n",
    "\n",
    "# How much (survived) trees:\n",
    "T = 34\n",
    "\n",
    "# Parameters for bootstrap\n",
    "\n",
    "# Data for each tree:\n",
    "N_T = int((df[target_col].value_counts()[1] - N_fraud_test)/2) # remaing data for fraud.\n",
    "N_V = N_T # keep balanced amount for each classe.\n",
    "\n",
    "# How much features:\n",
    "n_F_max = len(ds_cols)\n",
    "n_F_min = 20\n",
    "# From EDA: decision trees with small amount of features could be not so efficient.\n",
    "\n",
    "# Droped trees limit:\n",
    "D = 256\n",
    "# When a total of D trees are dropped, the validation threshold decreases delta_Th, restarting the counting.\n",
    "\n",
    "# Delta Threshold\n",
    "delta_th = 0.001\n",
    "th_start = 0.999\n",
    "get_best_tree = True\n",
    "# The validation threshold decreases dynamically as need to selection more specialized tree.\n",
    "\n",
    "# Metric in validation\n",
    "M = 'Accuracy'\n",
    "# This parameter have no effect, only to say which metric is used in validation process.\n",
    "\n",
    "#Seeds\n",
    "split_seeds = [43, 47, 53, 59]\n",
    "# One for each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T18:40:12.650347Z",
     "iopub.status.busy": "2021-09-20T18:40:12.649872Z",
     "iopub.status.idle": "2021-09-20T18:50:31.606722Z",
     "shell.execute_reply": "2021-09-20T18:50:31.605778Z",
     "shell.execute_reply.started": "2021-09-20T18:40:12.650310Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b6ae9a1abf442ab9b0adf4ad144372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Planting the forest:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-16:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tqdm/contrib/concurrent.py\u001b[0m in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmap_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/concurrent/futures/process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \"\"\"\n\u001b[0;32m--> 559\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    607\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52/1733102743.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     26\u001b[0m     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_parallel_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/random_forest_mc/model.py\u001b[0m in \u001b[0;36mfitParallel\u001b[0;34m(self, dataset, disable_progress_bar, max_workers, thread_parallel_method)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mfunc_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         out = func_map(\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurvivedTree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tqdm/contrib/concurrent.py\u001b[0m in \u001b[0;36mprocess_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mtqdm_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mtqdm_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lock_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mp_lock\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_executor_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtqdm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tqdm/contrib/concurrent.py\u001b[0m in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mmap_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmap_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/concurrent/futures/process.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor_manager_thread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor_manager_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;31m# To reduce the risk of opening too many files, remove references to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;31m# objects that use file descriptors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-12:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Splitting by unique values of the classes.\n",
    "df = df[ds_cols+[target_col]]\n",
    "df[target_col] = df[target_col].astype(str)\n",
    "df_fraud = df.query('Class == \"1\"').reset_index(drop=True).copy()\n",
    "df_truth = df.query('Class == \"0\"').reset_index(drop=True).copy()\n",
    "\n",
    "Results = []\n",
    "    \n",
    "# Each seed is a experiment.\n",
    "for seed in split_seeds:\n",
    "\n",
    "    # Start the experiment\n",
    "    df_fraud_train, df_fraud_test = train_test_split(df_fraud, test_size=N_fraud_test, random_state=seed)\n",
    "    df_truth_train, df_truth_test = train_test_split(df_truth, train_size=N_truth_train, test_size=N_truth_test, random_state=seed)\n",
    "    df_train = pd.concat([df_fraud_train, df_truth_train]).reset_index(drop=True)\n",
    "    df_test = pd.concat([df_fraud_test, df_truth_test]).reset_index(drop=True)\n",
    "    del df_fraud_test, df_truth_test, df_fraud_train, df_truth_train\n",
    "    \n",
    "    # Training step\n",
    "    cls = RandomForestMC(\n",
    "        n_trees=T, target_col='Class', max_discard_trees=D,\n",
    "        delta_th=delta_th, th_start=th_start,\n",
    "        batch_train_pclass=N_T, batch_val_pclass=N_V,\n",
    "        th_decease_verbose = False, get_best_tree=get_best_tree\n",
    "    )\n",
    "    cls.process_dataset(df_train)\n",
    "    cls.fitParallel(max_workers=16, thread_parallel_method=False)\n",
    "    y_pred = cls.testForest(df_test)\n",
    "    y_test = df_test[target_col].tolist()\n",
    "    F1_M = f1_score(y_test, y_pred, average='macro')\n",
    "    AUC_ROC_M = roc_auc_score(y_test, y_pred, average='macro')\n",
    "    RECALL = recall_score(y_test, y_pred, average='binary')\n",
    "    TP_1 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '1'])/y_test.count('1')\n",
    "    \n",
    "    Results.append((seed, 'RFMC', F1_M, AUC_ROC_M, RECALL, TP_1))\n",
    "    \n",
    "    MLPC = MLPClassifier(hidden_layer_sizes=(200,), max_iter=10000)\n",
    "    MLPC.fit(X_train_under, y_train_under)\n",
    "    y_pred = MLPC.predict(X_test)\n",
    "    F1_M = f1_score(y_test, y_pred, average='macro')\n",
    "    AUC_ROC_M = roc_auc_score(y_test, y_pred, average='macro')\n",
    "    RECALL = recall_score(y_test, y_pred, average='binary')\n",
    "    TP_1 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '1'])/y_test.count('1')\n",
    "    \n",
    "    Results.append((seed, 'MLPC', F1_M, AUC_ROC_M, RECALL, TP_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
