{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template \n",
    "\n",
    "- Author: Israel Oliveira [\\[e-mail\\]](mailto:'Israel%20Oliveira%20'<prof.israel@gmail.com>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T22:48:07.162533Z",
     "iopub.status.busy": "2021-09-20T22:48:07.162162Z",
     "iopub.status.idle": "2021-09-20T22:48:10.815715Z",
     "shell.execute_reply": "2021-09-20T22:48:10.813030Z",
     "shell.execute_reply.started": "2021-09-20T22:48:07.162441Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting random-forest-mc\n",
      "  Downloading random_forest_mc-0.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tqdm>=4.60 in /usr/local/lib/python3.9/site-packages (from random-forest-mc) (4.62.2)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/site-packages (from random-forest-mc) (1.20.3)\n",
      "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.9/site-packages (from random-forest-mc) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/site-packages (from pandas>=1.3->random-forest-mc) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/site-packages (from pandas>=1.3->random-forest-mc) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.3->random-forest-mc) (1.16.0)\n",
      "Installing collected packages: random-forest-mc\n",
      "Successfully installed random-forest-mc-0.3.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U random-forest-mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T22:48:10.823177Z",
     "iopub.status.busy": "2021-09-20T22:48:10.822094Z",
     "iopub.status.idle": "2021-09-20T22:48:10.871093Z",
     "shell.execute_reply": "2021-09-20T22:48:10.870211Z",
     "shell.execute_reply.started": "2021-09-20T22:48:10.823040Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T00:15:45.041611Z",
     "iopub.status.busy": "2021-09-21T00:15:45.041257Z",
     "iopub.status.idle": "2021-09-21T00:15:45.053301Z",
     "shell.execute_reply": "2021-09-21T00:15:45.052365Z",
     "shell.execute_reply.started": "2021-09-21T00:15:45.041570Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random_forest_mc.model import RandomForestMC\n",
    "from random_forest_mc.utils import load_file_json, dump_file_json, LoadDicts\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score\n",
    "from collections import Counter\n",
    "import hashlib\n",
    "from joblib import dump\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T22:48:12.435840Z",
     "iopub.status.busy": "2021-09-20T22:48:12.435541Z",
     "iopub.status.idle": "2021-09-20T22:48:12.446683Z",
     "shell.execute_reply": "2021-09-20T22:48:12.445392Z",
     "shell.execute_reply.started": "2021-09-20T22:48:12.435807Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# from glob import glob\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from matplotlib import rcParams\n",
    "# from cycler import cycler\n",
    "\n",
    "# rcParams['figure.figsize'] = 12, 8 # 18, 5\n",
    "# rcParams['axes.spines.top'] = False\n",
    "# rcParams['axes.spines.right'] = False\n",
    "# rcParams['axes.grid'] = True\n",
    "# rcParams['axes.prop_cycle'] = cycler(color=['#365977'])\n",
    "# rcParams['lines.linewidth'] = 2.5\n",
    "\n",
    "# import seaborn as sns\n",
    "# sns.set_theme()\n",
    "\n",
    "# pd.set_option(\"max_columns\", None)\n",
    "# pd.set_option(\"max_rows\", None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def md(arg):\n",
    "    display(Markdown(arg))\n",
    "\n",
    "# from pandas_profiling import ProfileReport\n",
    "# #report = ProfileReport(#DataFrame here#, minimal=True)\n",
    "# #report.to\n",
    "\n",
    "# import pyarrow.parquet as pq\n",
    "# #df = pq.ParquetDataset(path_to_folder_with_parquets, filesystem=None).read_pandas().to_pandas()\n",
    "\n",
    "# import json\n",
    "# def open_file_json(path,mode='r',var=None):\n",
    "#     if mode == 'w':\n",
    "#         with open(path,'w') as f:\n",
    "#             json.dump(var, f)\n",
    "#     if mode == 'r':\n",
    "#         with open(path,'r') as f:\n",
    "#             return json.load(f)\n",
    "\n",
    "# import functools\n",
    "# import operator\n",
    "# def flat(a):\n",
    "#     return functools.reduce(operator.iconcat, a, [])\n",
    "\n",
    "# import json\n",
    "# from glob import glob\n",
    "# from typing import NewType\n",
    "\n",
    "\n",
    "# DictsPathType = NewType(\"DictsPath\", str)\n",
    "\n",
    "\n",
    "# def open_file_json(path):\n",
    "#     with open(path, \"r\") as f:\n",
    "#         return json.load(f)\n",
    "\n",
    "# class LoadDicts:\n",
    "#     def __init__(self, dict_path: DictsPathType = \"./data\"):\n",
    "#         Dicts_glob = glob(f\"{dict_path}/*.json\")\n",
    "#         self.List = []\n",
    "#         self.Dict = {}\n",
    "#         for path_json in Dicts_glob:\n",
    "#             name = path_json.split(\"/\")[-1].replace(\".json\", \"\")\n",
    "#             self.List.append(name)\n",
    "#             self.Dict[name] = open_file_json(path_json)\n",
    "#             setattr(self, name, self.Dict[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T22:48:12.449127Z",
     "iopub.status.busy": "2021-09-20T22:48:12.447758Z",
     "iopub.status.idle": "2021-09-20T22:48:13.831627Z",
     "shell.execute_reply": "2021-09-20T22:48:13.828861Z",
     "shell.execute_reply.started": "2021-09-20T22:48:12.449088Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.9.7\n",
      "IPython version      : 7.27.0\n",
      "\n",
      "Compiler    : GCC 10.2.1 20210110\n",
      "OS          : Linux\n",
      "Release     : 5.11.0-7633-generic\n",
      "Machine     : x86_64\n",
      "Processor   : \n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: dbec514fccda877bfe759f3b85caca88c3f00944\n",
      "\n",
      "Git repo: https://github.com/ysraell/random-forest-mc.git\n",
      "\n",
      "Git branch: main\n",
      "\n",
      "pandas: 1.3.2\n",
      "joblib: 1.0.1\n",
      "numpy : 1.20.3\n",
      "\n",
      "CPU\t: Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz\n",
      "Mem:            15G\n",
      "Swap:          4.0G\n"
     ]
    }
   ],
   "source": [
    "# Run this cell before close.\n",
    "%watermark -d --iversion -b -r -g -m -v\n",
    "!cat /proc/cpuinfo |grep 'model name'|head -n 1 |sed -e 's/model\\ name/CPU/'\n",
    "!free -h |cut -d'i' -f1  |grep -v total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T23:27:30.958168Z",
     "iopub.status.busy": "2021-09-20T23:27:30.957812Z",
     "iopub.status.idle": "2021-09-20T23:27:30.965361Z",
     "shell.execute_reply": "2021-09-20T23:27:30.964474Z",
     "shell.execute_reply.started": "2021-09-20T23:27:30.958129Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['titanic', 'iris', 'creditcard', 'creditcard_trans_int', 'creditcard_trans_float'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts = LoadDicts(\"../tests/\")\n",
    "dataset_dict = dicts.datasets_metadata\n",
    "dataset_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T22:48:13.839677Z",
     "iopub.status.busy": "2021-09-20T22:48:13.837888Z",
     "iopub.status.idle": "2021-09-20T22:48:13.865121Z",
     "shell.execute_reply": "2021-09-20T22:48:13.863165Z",
     "shell.execute_reply.started": "2021-09-20T22:48:13.839567Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dfany2dfnumeric(dfA, dfB):\n",
    "    for col in dfA.columns:\n",
    "        mapper = {val: i for i,val in enumerate(dfA[col].unique().tolist()+dfB[col].unique().tolist())}\n",
    "        dfA[col] = dfA[col].apply(lambda x: mapper[x])\n",
    "        dfB[col] = dfB[col].apply(lambda x: mapper[x])\n",
    "    return dfA, dfB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tinanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T00:42:31.237347Z",
     "iopub.status.busy": "2021-09-21T00:42:31.236956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1bb009e7df49b4a3cfea882e3147f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Planting the forest:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bab0dd2888b45339a8d76b3a1c6212a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Planting the forest:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6659c8af771473f8ef98664b4d9a528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Planting the forest:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_name = \"titanic\"\n",
    "params = dataset_dict[ds_name]\n",
    "dataset = (\n",
    "    pd.read_csv(params[\"csv_path\"].replace('~','/work'))[params[\"ds_cols\"] + [params[\"target_col\"]]]\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "dataset[\"Age\"] = dataset[\"Age\"].astype(np.uint8)\n",
    "dataset[\"SibSp\"] = dataset[\"SibSp\"].astype(np.uint8)\n",
    "dataset[\"Pclass\"] = dataset[\"Pclass\"].astype(str)\n",
    "dataset[\"Fare\"] = dataset[\"Fare\"].astype(np.uint32)\n",
    "target_col = params['target_col']\n",
    "dataset = dataset[params['ds_cols']+[target_col]].dropna().reset_index(drop=True)\n",
    "dataset[target_col] = dataset[target_col].astype(str)\n",
    "\n",
    "test_size = 0.5\n",
    "max_test_size = 100\n",
    "max_train_size = 100\n",
    "\n",
    "split_seeds = [43, 47, 53, 59]\n",
    "#def fullCycleAnalysis(dataset,params,test_size_frac, max_test_size, max_train_size, split_seeds, )\n",
    "target_col = params['target_col']\n",
    "ds_cols = params[\"ds_cols\"]\n",
    "\n",
    "Results = []\n",
    "# Each seed is a experiment.\n",
    "for seed in split_seeds:\n",
    "    \n",
    "    df_train_list = []\n",
    "    df_test_list = []\n",
    "    df_classes = [dataset.query(f'{target_col} == \"{target_val}\"').reset_index(drop=True).copy() for target_val in dataset[target_col].unique()]\n",
    "    while df_classes:\n",
    "        df = df_classes.pop(0)\n",
    "        df_train, df_test = train_test_split(df, test_size=test_size, random_state=seed)\n",
    "        if df_train.shape[0] > max_train_size:\n",
    "            df_train = df_train.sample(n = max_train_size, random_state=seed)\n",
    "        if df_test.shape[0] > max_test_size:\n",
    "            df_test = df_test.sample(n = max_test_size, random_state=seed)\n",
    "        df_train_list.append(df_train.copy())\n",
    "        df_test_list.append(df_test.copy())\n",
    "        del df\n",
    "    dataset_train = pd.concat(df_train_list)\n",
    "    dataset_train = dataset_train.sample(dataset_train.shape[0]).reset_index(drop=True).copy()\n",
    "    del df_train_list\n",
    "    dataset_test = pd.concat(df_test_list)\n",
    "    dataset_test = dataset_test.sample(dataset_test.shape[0]).reset_index(drop=True).copy()\n",
    "    del df_test_list\n",
    "\n",
    "    y_test = dataset_test[target_col].tolist()\n",
    "    NT = dataset_train[target_col].value_counts().sort_values().min() \n",
    "    # Training step\n",
    "    cls = RandomForestMC(\n",
    "        n_trees=64, target_col=target_col, max_discard_trees=2,\n",
    "        th_start=0.9999, batch_train_pclass = NT // 2, batch_val_pclass = NT // 2\n",
    "    )\n",
    "    cls.process_dataset(dataset_train)\n",
    "    cls.fitParallel(max_workers=16, thread_parallel_method=False)\n",
    "    modeldict = cls.model2dict()\n",
    "    dump_file_json(f'/work/data/RandomForestMC_{ds_name}_{seed}.json', modeldict)\n",
    "    y_pred = cls.testForest(dataset_test)\n",
    "    F1_M = f1_score(y_test, y_pred, average='macro')\n",
    "    AUC_ROC_M = roc_auc_score(y_test, y_pred, average='macro')\n",
    "    RECALL = recall_score(y_test, y_pred, pos_label='1')\n",
    "    TP_1 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '1'])/y_test.count('1')\n",
    "    TP_0 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '0'])/y_test.count('0')\n",
    "    \n",
    "    Results.append((seed, 'RFMC', F1_M, AUC_ROC_M, RECALL, TP_1, TP_0))\n",
    "    \n",
    "    dataset_train_num, dataset_test_num = dfany2dfnumeric(dataset_train[ds_cols], dataset_test[ds_cols])\n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(dataset_train_num[ds_cols].to_numpy())  \n",
    "    # X_train = scaler.transform(dataset_train_num[ds_cols].to_numpy())  \n",
    "    # X_test = scaler.transform(dataset_test_num[ds_cols].to_numpy())  \n",
    "    \n",
    "    cls = RandomForestClassifier(n_estimators=400, n_jobs=-1)\n",
    "    cls.fit(dataset_train_num[ds_cols].to_numpy(), dataset_train[target_col].to_numpy())\n",
    "    dump(cls, f'/work/data/RandomForestClassifier_{ds_name}_{seed}.joblib')\n",
    "    y_pred = cls.predict(dataset_test_num[ds_cols].to_numpy()).tolist()\n",
    "    F1_M = f1_score(y_test, y_pred, average='macro')\n",
    "    AUC_ROC_M = roc_auc_score(y_test, y_pred, average='macro')\n",
    "    RECALL = recall_score(y_test, y_pred, pos_label='1')\n",
    "    TP_1 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '1'])/y_test.count('1')\n",
    "    TP_0 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '0'])/y_test.count('0')\n",
    "    \n",
    "    Results.append((seed, 'RF', F1_M, AUC_ROC_M, RECALL, TP_1, TP_0))   \n",
    "    \n",
    "    cls = MLPClassifier(hidden_layer_sizes=(200,), max_iter=10000)\n",
    "    cls.fit(dataset_train_num[ds_cols].to_numpy(), dataset_train[target_col].to_numpy())\n",
    "    dump(cls, f'/work/data/MLPClassifier_{ds_name}_{seed}.joblib')\n",
    "    y_pred = cls.predict(dataset_test_num[ds_cols].to_numpy()).tolist()\n",
    "    F1_M = f1_score(y_test, y_pred, average='macro')\n",
    "    AUC_ROC_M = roc_auc_score(y_test, y_pred, average='macro')\n",
    "    RECALL = recall_score(y_test, y_pred, pos_label='1')\n",
    "    TP_1 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '1'])/y_test.count('1')\n",
    "    TP_0 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '0'])/y_test.count('0')\n",
    "    \n",
    "    Results.append((seed, 'MLPC', F1_M, AUC_ROC_M, RECALL, TP_1, TP_0))\n",
    "    \n",
    "    del dataset_train, dataset_train_num, dataset_test_num\n",
    "    \n",
    "columns=['seed', 'MODEL', 'F1_M', 'AUC_ROC_M', 'RECALL', 'TP_1', 'TP_0']\n",
    "df_results = pd.DataFrame(Results, columns=columns)\n",
    "for model in df_results.MODEL.unique():\n",
    "    md(f'## {model}')\n",
    "    display(df_results[columns[1:]].query(f'MODEL == \"{model}\"').describe())\n",
    "    \n",
    "df_results.to_csv(f'/work/data/comparison_experiments_{ds_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Credit Card Fraude Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T00:20:05.503129Z",
     "iopub.status.busy": "2021-09-21T00:20:05.502421Z",
     "iopub.status.idle": "2021-09-21T00:21:12.864897Z",
     "shell.execute_reply": "2021-09-21T00:21:12.863816Z",
     "shell.execute_reply.started": "2021-09-21T00:20:05.503072Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f72d9b4049d4832a4ba8200f27b8d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Planting the forest:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b4c0b568814fbfb784601f43b549c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Planting the forest:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c0ea450608474593819d19b6ab0dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Planting the forest:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127ef6d05cde450b858dac807ab5bbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Planting the forest:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## RFMC"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_M</th>\n",
       "      <th>AUC_ROC_M</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>TP_1</th>\n",
       "      <th>TP_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.910577</td>\n",
       "      <td>0.91125</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.015240</td>\n",
       "      <td>0.01493</td>\n",
       "      <td>0.030957</td>\n",
       "      <td>0.030957</td>\n",
       "      <td>0.005774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.894044</td>\n",
       "      <td>0.89500</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.901612</td>\n",
       "      <td>0.90250</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.909258</td>\n",
       "      <td>0.91000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.918223</td>\n",
       "      <td>0.91875</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.929747</td>\n",
       "      <td>0.93000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           F1_M  AUC_ROC_M    RECALL      TP_1      TP_0\n",
       "count  4.000000    4.00000  4.000000  4.000000  4.000000\n",
       "mean   0.910577    0.91125  0.827500  0.827500  0.995000\n",
       "std    0.015240    0.01493  0.030957  0.030957  0.005774\n",
       "min    0.894044    0.89500  0.800000  0.800000  0.990000\n",
       "25%    0.901612    0.90250  0.807500  0.807500  0.990000\n",
       "50%    0.909258    0.91000  0.820000  0.820000  0.995000\n",
       "75%    0.918223    0.91875  0.840000  0.840000  1.000000\n",
       "max    0.929747    0.93000  0.870000  0.870000  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## RF"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_M</th>\n",
       "      <th>AUC_ROC_M</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>TP_1</th>\n",
       "      <th>TP_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.927340</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.967500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.017236</td>\n",
       "      <td>0.017078</td>\n",
       "      <td>0.036856</td>\n",
       "      <td>0.036856</td>\n",
       "      <td>0.009574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.904597</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.919830</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.929888</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.937398</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.972500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.944988</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           F1_M  AUC_ROC_M    RECALL      TP_1      TP_0\n",
       "count  4.000000   4.000000  4.000000  4.000000  4.000000\n",
       "mean   0.927340   0.927500  0.887500  0.887500  0.967500\n",
       "std    0.017236   0.017078  0.036856  0.036856  0.009574\n",
       "min    0.904597   0.905000  0.840000  0.840000  0.960000\n",
       "25%    0.919830   0.920000  0.877500  0.877500  0.960000\n",
       "50%    0.929888   0.930000  0.890000  0.890000  0.965000\n",
       "75%    0.937398   0.937500  0.900000  0.900000  0.972500\n",
       "max    0.944988   0.945000  0.930000  0.930000  0.980000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## MLPC"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_M</th>\n",
       "      <th>AUC_ROC_M</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>TP_1</th>\n",
       "      <th>TP_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.906080</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.93000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.026746</td>\n",
       "      <td>0.026575</td>\n",
       "      <td>0.051235</td>\n",
       "      <td>0.051235</td>\n",
       "      <td>0.03559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.884349</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.88000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.884835</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.91750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.899989</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.94000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.921234</td>\n",
       "      <td>0.921250</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.95250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.939994</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.96000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           F1_M  AUC_ROC_M    RECALL      TP_1     TP_0\n",
       "count  4.000000   4.000000  4.000000  4.000000  4.00000\n",
       "mean   0.906080   0.906250  0.882500  0.882500  0.93000\n",
       "std    0.026746   0.026575  0.051235  0.051235  0.03559\n",
       "min    0.884349   0.885000  0.810000  0.810000  0.88000\n",
       "25%    0.884835   0.885000  0.870000  0.870000  0.91750\n",
       "50%    0.899989   0.900000  0.895000  0.895000  0.94000\n",
       "75%    0.921234   0.921250  0.907500  0.907500  0.95250\n",
       "max    0.939994   0.940000  0.930000  0.930000  0.96000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_name = \"creditcard_trans_int\"\n",
    "params = dataset_dict[ds_name]\n",
    "dataset = (\n",
    "    pd.read_csv(params[\"csv_path\"].replace('~','/work'))[params[\"ds_cols\"] + [params[\"target_col\"]]]\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "target_col = params['target_col']\n",
    "dataset = dataset[params['ds_cols']+[target_col]].dropna().reset_index(drop=True)\n",
    "dataset[target_col] = dataset[target_col].astype(str)\n",
    "\n",
    "test_size = 0.5\n",
    "max_test_size = 100\n",
    "max_train_size = 100\n",
    "\n",
    "split_seeds = [43, 47, 53, 59]\n",
    "#def fullCycleAnalysis(dataset,params,test_size_frac, max_test_size, max_train_size, split_seeds, )\n",
    "target_col = params['target_col']\n",
    "ds_cols = params[\"ds_cols\"]\n",
    "\n",
    "Results = []\n",
    "# Each seed is a experiment.\n",
    "for seed in split_seeds:\n",
    "    \n",
    "    df_train_list = []\n",
    "    df_test_list = []\n",
    "    df_classes = [dataset.query(f'{target_col} == \"{target_val}\"').reset_index(drop=True).copy() for target_val in dataset[target_col].unique()]\n",
    "    while df_classes:\n",
    "        df = df_classes.pop(0)\n",
    "        df_train, df_test = train_test_split(df, test_size=test_size, random_state=seed)\n",
    "        if df_train.shape[0] > max_train_size:\n",
    "            df_train = df_train.sample(n = max_train_size, random_state=seed)\n",
    "        if df_test.shape[0] > max_test_size:\n",
    "            df_test = df_test.sample(n = max_test_size, random_state=seed)\n",
    "        df_train_list.append(df_train.copy())\n",
    "        df_test_list.append(df_test.copy())\n",
    "        del df\n",
    "    dataset_train = pd.concat(df_train_list)\n",
    "    dataset_train = dataset_train.sample(dataset_train.shape[0]).reset_index(drop=True).copy()\n",
    "    del df_train_list\n",
    "    dataset_test = pd.concat(df_test_list)\n",
    "    dataset_test = dataset_test.sample(dataset_test.shape[0]).reset_index(drop=True).copy()\n",
    "    del df_test_list\n",
    "\n",
    "    y_test = dataset_test[target_col].astype(str).tolist()\n",
    "    NT = dataset_train[target_col].value_counts().sort_values().min() \n",
    "    # Training step\n",
    "    cls = RandomForestMC(\n",
    "        n_trees=64, target_col=target_col, max_discard_trees=2,\n",
    "        th_start=0.9999, batch_train_pclass = NT // 2, batch_val_pclass = NT // 2\n",
    "    )\n",
    "    cls.process_dataset(dataset_train)\n",
    "    cls.fitParallel(max_workers=16, thread_parallel_method=False)\n",
    "    modeldict = cls.model2dict()\n",
    "    dump_file_json(f'/work/data/RandomForestMC_{ds_name}_{seed}.json', modeldict)\n",
    "    y_pred = cls.testForest(dataset_test)\n",
    "    F1_M = f1_score(y_test, y_pred, average='macro')\n",
    "    AUC_ROC_M = roc_auc_score(y_test, y_pred, average='macro')\n",
    "    RECALL = recall_score(y_test, y_pred, pos_label='1')\n",
    "    TP_1 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '1'])/y_test.count('1')\n",
    "    TP_0 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '0'])/y_test.count('0')\n",
    "    \n",
    "    Results.append((seed, 'RFMC', F1_M, AUC_ROC_M, RECALL, TP_1, TP_0))\n",
    "    \n",
    "    dataset_train_num, dataset_test_num = dataset_train[ds_cols], dataset_test[ds_cols]\n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(dataset_train_num[ds_cols].to_numpy())  \n",
    "    # X_train = scaler.transform(dataset_train_num[ds_cols].to_numpy())  \n",
    "    # X_test = scaler.transform(dataset_test_num[ds_cols].to_numpy())  \n",
    "    \n",
    "    cls = RandomForestClassifier(n_estimators=400, n_jobs=-1)\n",
    "    cls.fit(dataset_train_num[ds_cols].to_numpy(), dataset_train[target_col].to_numpy())\n",
    "    dump(cls, f'/work/data/RandomForestClassifier_{ds_name}_{seed}.joblib')\n",
    "    \n",
    "    y_pred = cls.predict(dataset_test_num[ds_cols].to_numpy()).tolist()\n",
    "    F1_M = f1_score(y_test, y_pred, average='macro')\n",
    "    AUC_ROC_M = roc_auc_score(y_test, y_pred, average='macro')\n",
    "    RECALL = recall_score(y_test, y_pred, pos_label='1')\n",
    "    TP_1 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '1'])/y_test.count('1')\n",
    "    TP_0 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '0'])/y_test.count('0')\n",
    "    \n",
    "    Results.append((seed, 'RF', F1_M, AUC_ROC_M, RECALL, TP_1, TP_0))   \n",
    "    \n",
    "    cls = MLPClassifier(hidden_layer_sizes=(200,), max_iter=10000)\n",
    "    cls.fit(dataset_train_num[ds_cols].to_numpy(), dataset_train[target_col].to_numpy())\n",
    "    dump(cls, f'/work/data/MLPClassifier_{ds_name}_{seed}.joblib')\n",
    "    y_pred = cls.predict(dataset_test_num[ds_cols].to_numpy()).tolist()\n",
    "    F1_M = f1_score(y_test, y_pred, average='macro')\n",
    "    AUC_ROC_M = roc_auc_score(y_test, y_pred, average='macro')\n",
    "    RECALL = recall_score(y_test, y_pred, pos_label='1')\n",
    "    TP_1 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '1'])/y_test.count('1')\n",
    "    TP_0 = sum([ p == t for p,t in zip(y_pred,y_test) if t == '0'])/y_test.count('0')\n",
    "    \n",
    "    Results.append((seed, 'MLPC', F1_M, AUC_ROC_M, RECALL, TP_1, TP_0))\n",
    "    \n",
    "    del dataset_train, dataset_train_num, dataset_test_num\n",
    "    \n",
    "columns=['seed', 'MODEL', 'F1_M', 'AUC_ROC_M', 'RECALL', 'TP_1', 'TP_0']\n",
    "df_results = pd.DataFrame(Results, columns=columns)\n",
    "for model in df_results.MODEL.unique():\n",
    "    md(f'## {model}')\n",
    "    display(df_results[columns[1:]].query(f'MODEL == \"{model}\"').describe())\n",
    "    \n",
    "df_results.to_csv(f'/work/data/comparison_experiments_{ds_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
